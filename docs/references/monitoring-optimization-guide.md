# ç›‘æ§ç³»ç»Ÿä¼˜åŒ–æŒ‡å—

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2026-01-19
**æ‰€å±é˜¶æ®µ**: é˜¶æ®µ 4

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç›‘æ§æ¶æ„](#ç›‘æ§æ¶æ„)
- [Sentry é›†æˆ](#sentry-é›†æˆ)
- [Prometheus é›†æˆ](#prometheus-é›†æˆ)
- [Grafana Dashboard](#grafana-dashboard)
- [æ—¥å¿—ä¼˜åŒ–](#æ—¥å¿—ä¼˜åŒ–)
- [å‘Šè­¦é…ç½®](#å‘Šè­¦é…ç½®)
- [å®æ–½æ­¥éª¤](#å®æ–½æ­¥éª¤)

---

## æ¦‚è¿°

### ç›‘æ§ç›®æ ‡

1. **é”™è¯¯è¿½è¸ª** - æ•è·å’Œåˆ†æåº”ç”¨é”™è¯¯
2. **æ€§èƒ½ç›‘æ§** - è¿½è¸ªå…³é”®æ€§èƒ½æŒ‡æ ‡
3. **ä¸šåŠ¡æŒ‡æ ‡** - ç›‘æ§ä»»åŠ¡å¤„ç†æƒ…å†µ
4. **å¯è§†åŒ–å±•ç¤º** - ç›´è§‚çš„ä»ªè¡¨æ¿

### ç›‘æ§æŠ€æœ¯æ ˆ

```yaml
é”™è¯¯è¿½è¸ª: Sentry
æŒ‡æ ‡é‡‡é›†: Prometheus
å¯è§†åŒ–: Grafana
æ—¥å¿—: Winston + Elasticsearch
APM: OpenTelemetry (å¯é€‰)
```

---

## ç›‘æ§æ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         åº”ç”¨å±‚                          â”‚
â”‚  - Error Capture (Sentry)               â”‚
â”‚  - Metrics Export (Prometheus)         â”‚
â”‚  - Structured Logging (Winston)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         é‡‡é›†å±‚                          â”‚
â”‚  - Sentry SDK                          â”‚
â”‚  - prom-client                         â”‚
â”‚  - winston transports                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å­˜å‚¨å±‚                          â”‚
â”‚  - Sentry Cloud                        â”‚
â”‚  - Prometheus TSDB                     â”‚
â”‚  - Elasticsearch (Logs)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å¯è§†åŒ–å±‚                        â”‚
â”‚  - Sentry Dashboard                    â”‚
â”‚  - Grafana Dashboard                   â”‚
â”‚  - Kibana (Logs)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Sentry é›†æˆ

### åˆå§‹åŒ–é…ç½®

```typescript
// æ–‡ä»¶: src/infrastructure/monitoring/sentry.ts

import * as Sentry from '@sentry/node';
import { nodeProfilingIntegration } from '@sentry/profiling-node';

export class SentryService {
  initialize(dsn: string, environment: string) {
    Sentry.init({
      dsn,
      environment,
      // æ€§èƒ½ç›‘æ§
      integrations: [
        nodeProfilingIntegration(),
      ],
      // é‡‡æ ·ç‡
      tracesSampleRate: environment === 'production' ? 0.1 : 1.0,
      // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
      beforeSend(event, hint) {
        return this.filterSensitiveData(event);
      },
      // ç¯å¢ƒä¿¡æ¯
      release: process.env.APP_VERSION || '1.0.0',
      // ä¸Šä¸‹æ–‡
      initialScope: {
        tags: {
          service: 'content-creator',
          node_version: process.version,
        },
      },
    });

    // å…¨å±€é”™è¯¯å¤„ç†
    this.setupGlobalHandlers();
  }

  private filterSensitiveData(event: Sentry.Event) {
    // ç§»é™¤æ•æ„Ÿä¿¡æ¯
    if (event.request) {
      delete event.request.cookies;
      delete event.request.headers;
    }

    // è¿‡æ»¤ç‰¹å®šçš„é”™è¯¯
    if (event.exception) {
      const message = event.exception.values?.[0]?.value;
      if (this.shouldIgnoreError(message)) {
        return null; // å¿½ç•¥æ­¤é”™è¯¯
      }
    }

    return event;
  }

  private shouldIgnoreError(message?: string): boolean {
    const ignorePatterns = [
      /API key/i,
      /secret/i,
      /password/i,
      /ECONNREFUSED/,  // Redis è¿æ¥é”™è¯¯ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    ];

    return ignorePatterns.some(pattern =>
      pattern.test(message || '')
    );
  }

  private setupGlobalHandlers() {
    // æœªæ•è·çš„å¼‚å¸¸
    process.on('uncaughtException', (error) => {
      Sentry.captureException(error);
      // ç»™æ—¥å¿—è®°å½•æ—¶é—´
      setTimeout(() => process.exit(1), 1000);
    });

    // æœªå¤„ç†çš„ Promise æ‹’ç»
    process.on('unhandledRejection', (reason) => {
      Sentry.captureException(reason as Error);
    });
  }

  captureException(error: Error, context?: any) {
    Sentry.withScope((scope) => {
      if (context) {
        scope.setContext('custom', context);
      }
      Sentry.captureException(error);
    });
  }

  captureMessage(message: string, level: 'info' | 'warning' | 'error' = 'info') {
    Sentry.captureMessage(message, { level });
  }

  // æ·»åŠ é¢åŒ…å±‘ï¼ˆç”¨äºè¿½è¸ªç”¨æˆ·è·¯å¾„ï¼‰
  addBreadcrumb(category: string, message: string, data?: any) {
    Sentry.addBreadcrumb({
      category,
      message,
      level: 'info',
      data,
    });
  }

  // è®¾ç½®ç”¨æˆ·ä¿¡æ¯
  setUser(user: { id: string; email?: string; [key: string]: any }) {
    Sentry.setUser(user);
  }

  // æ€§èƒ½è¿½è¸ª
  startTransaction(name: string, op: string) {
    return Sentry.startSpan({ name, op });
  }
}

// å¯¼å‡ºå•ä¾‹
export const sentryService = new SentryService();
```

### ä½¿ç”¨ç¤ºä¾‹

```typescript
// åœ¨æ§åˆ¶å™¨ä¸­ä½¿ç”¨
import { sentryService } from './sentry.js';

export class TaskController {
  async createTask(req: Request, res: Response) {
    const transaction = sentryService.startTransaction('createTask', 'function');

    try {
      // æ·»åŠ é¢åŒ…å±‘
      sentryService.addBreadcrumb('http', 'Task creation started', {
        url: req.url,
        method: req.method
      });

      // ä¸šåŠ¡é€»è¾‘
      const task = await this.service.createTask(req.body);

      // è®¾ç½®ç”¨æˆ·
      sentryService.setUser({ id: req.user.id });

      return res.json(task);
    } catch (error) {
      // æ•è·å¼‚å¸¸å¹¶åŒ…å«ä¸Šä¸‹æ–‡
      sentryService.captureException(error as Error, {
        taskData: req.body,
        userId: req.user?.id
      });

      throw error;
    } finally {
      transaction.end();
    }
  }
}
```

---

## Prometheus é›†æˆ

### æŒ‡æ ‡å®šä¹‰

```typescript
// æ–‡ä»¶: src/infrastructure/monitoring/metrics.ts

import { register, Counter, Histogram, Gauge, Summary } from 'prom-client';

export class MetricsService {
  // ä»»åŠ¡æŒ‡æ ‡
  readonly taskCreated = new Counter({
    name: 'task_created_total',
    help: 'Total number of tasks created',
    labelNames: ['mode', 'type']
  });

  readonly taskCompleted = new Counter({
    name: 'task_completed_total',
    help: 'Total number of tasks completed',
    labelNames: ['mode', 'type', 'status']
  });

  readonly taskFailed = new Counter({
    name: 'task_failed_total',
    help: 'Total number of tasks failed',
    labelNames: ['mode', 'type', 'error_type']
  });

  readonly taskDuration = new Histogram({
    name: 'task_duration_seconds',
    help: 'Task execution duration in seconds',
    labelNames: ['mode', 'type', 'status'],
    buckets: [10, 30, 60, 120, 300, 600, 1800] // 10s-30min
  });

  // LLM æŒ‡æ ‡
  readonly llmRequestTotal = new Counter({
    name: 'llm_request_total',
    help: 'Total number of LLM requests',
    labelNames: ['model', 'operation']
  });

  readonly llmRequestDuration = new Histogram({
    name: 'llm_request_duration_seconds',
    help: 'LLM request duration in seconds',
    labelNames: ['model', 'operation'],
    buckets: [1, 5, 10, 30, 60, 120] // 1s-2min
  });

  readonly llmTokenUsage = new Counter({
    name: 'llm_token_usage_total',
    help: 'Total LLM token usage',
    labelNames: ['model', 'type'] // type: prompt/completion
  });

  readonly llmRetryTotal = new Counter({
    name: 'llm_retry_total',
    help: 'Total number of LLM retries',
    labelNames: ['model', 'reason']
  });

  // é˜Ÿåˆ—æŒ‡æ ‡
  readonly queueWaitingTasks = new Gauge({
    name: 'queue_waiting_tasks',
    help: 'Number of tasks waiting in queue',
    labelNames: ['queue_name']
  });

  readonly queueActiveTasks = new Gauge({
    name: 'queue_active_tasks',
    help: 'Number of tasks being processed',
    labelNames: ['queue_name']
  });

  readonly queueJobDuration = new Histogram({
    name: 'queue_job_duration_seconds',
    help: 'Queue job processing duration',
    labelNames: ['queue_name', 'status'],
    buckets: [5, 10, 30, 60, 300, 600]
  });

  // Worker æŒ‡æ ‡
  readonly workerActive = new Gauge({
    name: 'worker_active_total',
    help: 'Number of active workers',
    labelNames: ['worker_id']
  });

  readonly workerConcurrency = new Gauge({
    name: 'worker_concurrent_tasks',
    help: 'Number of concurrent tasks per worker',
    labelNames: ['worker_id']
  });

  // è´¨é‡æ£€æŸ¥æŒ‡æ ‡
  readonly qualityCheckDuration = new Histogram({
    name: 'quality_check_duration_seconds',
    help: 'Quality check execution duration',
    labelNames: ['check_type'], // hard_rule/soft_scoring
    buckets: [0.1, 0.5, 1, 5, 10, 30]
  });

  readonly qualityCheckScore = new Gauge({
    name: 'quality_check_score',
    help: 'Quality check score',
    labelNames: ['dimension'] // relevance/coherence/completeness/readability
  });

  readonly qualityCheckPassRate = new Gauge({
    name: 'quality_check_pass_rate',
    help: 'Quality check pass rate',
    labelNames: ['check_type']
  });

  // ç³»ç»ŸæŒ‡æ ‡
  readonly memoryUsage = new Gauge({
    name: 'process_memory_usage_bytes',
    help: 'Process memory usage in bytes'
  });

  readonly cpuUsage = new Gauge({
    name: 'process_cpu_usage_percent',
    help: 'Process CPU usage percentage'
  });

  // ç¼“å­˜æŒ‡æ ‡
  readonly cacheHitRate = new Gauge({
    name: 'cache_hit_rate',
    help: 'Cache hit rate',
    labelNames: ['cache_type'] // llm/search/quality
  });

  readonly cacheSize = new Gauge({
    name: 'cache_size',
    help: 'Cache size',
    labelNames: ['cache_type']
  });

  // è®°å½•æŒ‡æ ‡çš„æ–¹æ³•
  recordTaskCreation(mode: string, type: string) {
    this.taskCreated.inc({ mode, type });
  }

  recordTaskCompletion(mode: string, type: string, status: string, duration: number) {
    this.taskCompleted.inc({ mode, type, status });
    this.taskDuration.observe({ mode, type, status }, duration);
  }

  recordTaskFailure(mode: string, type: string, errorType: string) {
    this.taskFailed.inc({ mode, type, error_type: errorType });
  }

  recordLLMRequest(model: string, operation: string, duration: number, tokens: { prompt: number; completion: number }) {
    this.llmRequestTotal.inc({ model, operation });
    this.llmRequestDuration.observe({ model, operation }, duration);
    this.llmTokenUsage.inc({ model, type: 'prompt' }, tokens.prompt);
    this.llmTokenUsage.inc({ model, type: 'completion' }, tokens.completion);
  }

  recordLLMRetry(model: string, reason: string) {
    this.llmRetryTotal.inc({ model, reason });
  }

  updateQueueStats(queueName: string, stats: QueueStats) {
    this.queueWaitingTasks.set({ queue_name: queueName }, stats.waiting);
    this.queueActiveTasks.set({ queue_name: queueName }, stats.active);
  }

  recordQualityCheck(checkType: string, duration: number, score?: number, dimension?: string) {
    this.qualityCheckDuration.observe({ check_type: checkType }, duration);

    if (score !== undefined && dimension) {
      this.qualityCheckScore.set({ dimension }, score);
    }
  }

  // å®šæœŸæ›´æ–°ç³»ç»ŸæŒ‡æ ‡
  startSystemMetricsCollection(interval: number = 5000) {
    setInterval(() => {
      const memUsage = process.memoryUsage();
      this.memoryUsage.set(memUsage.heapUsed);
    }, interval);
  }

  // æš´éœ²æŒ‡æ ‡ç«¯ç‚¹
  getMetrics() {
    return register.metrics();
  }
}

// å¯¼å‡ºå•ä¾‹
export const metricsService = new MetricsService();
```

### HTTP ç«¯ç‚¹

```typescript
// æ–‡ä»¶: src/api/metrics.routes.ts

import { Router } from 'express';
import { metricsService } from '../infrastructure/monitoring/metrics.js';

export function createMetricsRouter(): Router {
  const router = Router();

  // Prometheus æŒ‡æ ‡ç«¯ç‚¹
  router.get('/metrics', async (req, res) => {
    res.set('Content-Type', register.contentType);
    res.end(await metricsService.getMetrics());
  });

  // è‡ªå®šä¹‰ç»Ÿè®¡ç«¯ç‚¹
  router.get('/api/stats', async (req, res) => {
    const stats = {
      tasks: {
        created: await metricsService.taskCreated.get(),
        completed: await metricsService.taskCompleted.get(),
        failed: await metricsService.taskFailed.get(),
      },
      llm: {
        requests: await metricsService.llmRequestTotal.get(),
        tokenUsage: await metricsService.llmTokenUsage.get(),
      },
      queue: {
        waiting: await metricsService.queueWaitingTasks.get(),
        active: await metricsService.queueActiveTasks.get(),
      }
    };

    res.json(stats);
  });

  return router;
}
```

---

## Grafana Dashboard

### Dashboard é…ç½®

```json
{
  "dashboard": {
    "title": "Content Creator ç›‘æ§é¢æ¿",
    "tags": ["content-creator"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "ä»»åŠ¡åˆ›å»ºè¶‹åŠ¿",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(task_created_total[5m])",
            "legendFormat": "{{mode}} - {{type}}"
          }
        ]
      },
      {
        "id": 2,
        "title": "ä»»åŠ¡æ‰§è¡Œæ—¶é•¿",
        "type": "heatmap",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(task_duration_seconds_bucket[5m]))",
            "legendFormat": "{{mode}} - {{status}}"
          }
        ]
      },
      {
        "id": 3,
        "title": "LLM è¯·æ±‚é€Ÿç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(llm_request_total[1m])",
            "legendFormat": "{{model}} - {{operation}}"
          }
        ]
      },
      {
        "id": 4,
        "title": "Token ä½¿ç”¨é‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(llm_token_usage_total[5m])",
            "legendFormat": "{{model}} - {{type}}"
          }
        ]
      },
      {
        "id": 5,
        "title": "é˜Ÿåˆ—çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "queue_waiting_tasks",
            "legendFormat": "ç­‰å¾…ä¸­"
          },
          {
            "expr": "queue_active_tasks",
            "legendFormat": "å¤„ç†ä¸­"
          }
        ]
      },
      {
        "id": 6,
        "title": "è´¨é‡æ£€æŸ¥åˆ†æ•°",
        "type": "gauge",
        "targets": [
          {
            "expr": "avg(quality_check_score)",
            "legendFormat": "å¹³å‡åˆ†"
          }
        ]
      }
    ]
  }
}
```

---

## æ—¥å¿—ä¼˜åŒ–

### Winston é…ç½®

```typescript
// æ–‡ä»¶: src/infrastructure/logging/winston.ts

import winston from 'winston';
import DailyRotateFile from 'winston-daily-rotate-file';

export class LoggingService {
  private logger: winston.Logger;

  constructor() {
    this.logger = winston.createLogger({
      level: process.env.LOG_LEVEL || 'info',
      format: winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.errors({ stack: true }),
        winston.format.splat(),
        winston.format.json()
      ),
      defaultMeta: {
        service: 'content-creator',
        environment: process.env.NODE_ENV,
      },
      transports: [
        // é”™è¯¯æ—¥å¿—
        new DailyRotateFile({
          filename: 'logs/error-%DATE%.log',
          datePattern: 'YYYY-MM-DD',
          level: 'error',
          maxSize: '20m',
          maxFiles: '14d'
        }),
        // ç»„åˆæ—¥å¿—
        new DailyRotateFile({
          filename: 'logs/combined-%DATE%.log',
          datePattern: 'YYYY-MM-DD',
          maxSize: '20m',
          maxFiles: '14d'
        }),
        // æ§åˆ¶å°è¾“å‡ºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        ...(process.env.NODE_ENV === 'development' ? [
          new winston.transports.Console({
            format: winston.format.combine(
              winston.format.colorize(),
              winston.format.simple()
            )
          })
        ] : [])
      ]
    });
  }

  info(message: string, meta?: any) {
    this.logger.info(message, meta);
  }

  warn(message: string, meta?: any) {
    this.logger.warn(message, meta);
  }

  error(message: string, meta?: any) {
    this.logger.error(message, meta);
  }

  debug(message: string, meta?: any) {
    this.logger.debug(message, meta);
  }

  // ä¸Šä¸‹æ–‡æ—¥å¿—
  logWithContext(context: string, message: string, meta?: any) {
    this.logger.info({ context, message, ...meta });
  }
}

// å¯¼å‡ºå•ä¾‹
export const loggingService = new LoggingService();

// å¿«æ·æ–¹æ³•
export const logger = {
  info: (message: string, meta?: any) => loggingService.info(message, meta),
  warn: (message: string, meta?: any) => loggingService.warn(message, meta),
  error: (message: string, meta?: any) => loggingService.error(message, meta),
  debug: (message: string, meta?: any) => loggingService.debug(message, meta),
};
```

### ç»“æ„åŒ–æ—¥å¿—ç¤ºä¾‹

```typescript
// ä»»åŠ¡åˆ›å»ºæ—¥å¿—
logger.info('Task created', {
  taskId: 'task-123',
  mode: 'async',
  topic: 'AI æŠ€æœ¯',
  userId: 'user-456',
  duration: 1234,
});

// é”™è¯¯æ—¥å¿—
logger.error('LLM request failed', {
  error: error.message,
  stack: error.stack,
  model: 'deepseek-chat',
  operation: 'generate',
  attempt: 2,
  maxAttempts: 3,
  taskId: 'task-123',
});

// æ€§èƒ½æ—¥å¿—
logger.info('Task completed', {
  taskId: 'task-123',
  status: 'completed',
  duration: 180,
  steps: {
    search: 2,
    organize: 28,
    write: 36,
    qualityCheck: 114,
  },
  tokenUsage: {
    prompt: 1500,
    completion: 2000,
  },
});
```

---

## å‘Šè­¦é…ç½®

### Prometheus å‘Šè­¦è§„åˆ™

```yaml
# prometheus/alerts.yml

groups:
  - name: content_creator_alerts
    interval: 30s
    rules:
      # é«˜é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: rate(task_failed_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "ä»»åŠ¡å¤±è´¥ç‡è¿‡é«˜"
          description: "5åˆ†é’Ÿå†…ä»»åŠ¡å¤±è´¥ç‡è¶…è¿‡ 10%"

      # ä»»åŠ¡ç§¯å‹
      - alert: QueueBacklog
        expr: queue_waiting_tasks > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é˜Ÿåˆ—ç§¯å‹ä¸¥é‡"
          description: "ç­‰å¾…ä¸­çš„ä»»åŠ¡è¶…è¿‡ 100 ä¸ª"

      # LLM API æ…¢
      - alert: SlowLLMResponse
        expr: histogram_quantile(0.95, rate(llm_request_duration_seconds_bucket[5m])) > 30
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "LLM å“åº”æ…¢"
          description: "95åˆ†ä½å“åº”æ—¶é—´è¶…è¿‡ 30ç§’"

      # Worker ä¸æ´»è·ƒ
      - alert: WorkerInactive
        expr: worker_active_total == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æ‰€æœ‰ Worker ä¸å¯ç”¨"
          description: "æ²¡æœ‰æ´»è·ƒçš„ Worker åœ¨å¤„ç†ä»»åŠ¡"

      # å†…å­˜ä½¿ç”¨è¿‡é«˜
      - alert: HighMemoryUsage
        expr: process_memory_usage_bytes / 1024 / 1024 / 1024 > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å†…å­˜ä½¿ç”¨è¿‡é«˜"
          description: "è¿›ç¨‹å†…å­˜ä½¿ç”¨è¶…è¿‡ 2GB"
```

### Sentry å‘Šè­¦

```typescript
// Sentry å‘Šè­¦è§„åˆ™é…ç½®
const alertRules = {
  // é”™è¯¯ç‡å‘Šè­¦
  highErrorRate: {
    condition: 'error_rate > 0.05', // 5%
    duration: '5m',
    severity: 'warning'
  },

  // ç‰¹å®šé”™è¯¯å‘Šè­¦
  criticalError: {
    patterns: [
      'ECONNREFUSED',
      'ETIMEDOUT',
      'Database connection failed'
    ],
    severity: 'critical'
  },

  // LLM API é”™è¯¯
  llmAPIError: {
    patterns: [
      'LLM API error',
      'Rate limit exceeded'
    ],
    severity: 'warning'
  }
};
```

---

## å®æ–½æ­¥éª¤

### Step 1: å®‰è£…ä¾èµ–

```bash
pnpm add @sentry/node @sentry/profiling-node
pnpm add prom-client
pnpm add winston winston-daily-rotate-file
pnpm add -D @types/winston
```

### Step 2: åˆå§‹åŒ– Sentry

```typescript
// src/index.ts
import { sentryService } from './infrastructure/monitoring/sentry.js';

// åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–
if (process.env.SENTRY_DSN) {
  sentryService.initialize(
    process.env.SENTRY_DSN,
    process.env.NODE_ENV || 'development'
  );
}
```

### Step 3: æš´éœ² Prometheus ç«¯ç‚¹

```typescript
// src/api/index.ts
import { createMetricsRouter } from './api/metrics.routes.js';

app.use('/metrics', createMetricsRouter());
```

### Step 4: é…ç½® Grafana

1. æ·»åŠ  Prometheus æ•°æ®æº
2. å¯¼å…¥ Dashboard é…ç½®
3. é…ç½®å‘Šè­¦è§„åˆ™
4. è®¾ç½®é€šçŸ¥æ¸ é“ï¼ˆé‚®ä»¶/Slack/é’‰é’‰ï¼‰

---

## ç›‘æ§æœ€ä½³å®è·µ

### 1. åˆ†å±‚ç›‘æ§

```
åº”ç”¨å±‚ç›‘æ§ â†’ ä¸šåŠ¡æŒ‡æ ‡ï¼ˆä»»åŠ¡åˆ›å»ºã€å®Œæˆï¼‰
  â†“
æœåŠ¡å±‚ç›‘æ§ â†’ LLM è°ƒç”¨ã€æ•°æ®åº“æŸ¥è¯¢
  â†“
ç³»ç»Ÿå±‚ç›‘æ§ â†’ CPUã€å†…å­˜ã€ç½‘ç»œ
```

### 2. é»„é‡‘æŒ‡æ ‡

- **å»¶è¿Ÿ** (Latency) - P50, P95, P99
- **æµé‡** (Traffic) - QPSã€å¹¶å‘æ•°
- **é”™è¯¯** (Errors) - é”™è¯¯ç‡ã€é”™è¯¯ç±»å‹
- **é¥±å’Œåº¦** (Saturation) - CPUã€å†…å­˜ä½¿ç”¨ç‡

### 3. å‘Šè­¦ç­–ç•¥

- **Critical** - ç«‹å³é€šçŸ¥ï¼ˆç”µè¯/çŸ­ä¿¡ï¼‰
- **Warning** - å»¶è¿Ÿé€šçŸ¥ï¼ˆé‚®ä»¶/IMï¼‰
- **Info** - è®°å½•ä½†ä¸é€šçŸ¥

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2026-01-19
**ç‰ˆæœ¬**: 1.0
