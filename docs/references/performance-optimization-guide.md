# æ€§èƒ½ä¼˜åŒ–æŒ‡å—

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2026-01-19
**æ‰€å±é˜¶æ®µ**: é˜¶æ®µ 4

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç¼“å­˜ä¼˜åŒ–](#ç¼“å­˜ä¼˜åŒ–)
- [æ•°æ®åº“ä¼˜åŒ–](#æ•°æ®åº“ä¼˜åŒ–)
- [LLM è°ƒç”¨ä¼˜åŒ–](#llm-è°ƒç”¨ä¼˜åŒ–)
- [å¹¶å‘ä¼˜åŒ–](#å¹¶å‘ä¼˜åŒ–)
- [å†…å­˜ä¼˜åŒ–](#å†…å­˜ä¼˜åŒ–)
- [ç½‘ç»œä¼˜åŒ–](#ç½‘ç»œä¼˜åŒ–)
- [æ€§èƒ½æµ‹è¯•](#æ€§èƒ½æµ‹è¯•)

---

## æ¦‚è¿°

### ä¼˜åŒ–ç›®æ ‡

- âœ… å‡å°‘å“åº”æ—¶é—´ï¼ˆç«¯åˆ°ç«¯ < 5åˆ†é’Ÿï¼‰
- âœ… æé«˜ååé‡ï¼ˆæ—¥å¤„ç† 3000+ ä»»åŠ¡ï¼‰
- âœ… é™ä½èµ„æºä½¿ç”¨ï¼ˆå†…å­˜ < 2GB/Workerï¼‰
- âœ… å‡å°‘ API è°ƒç”¨æˆæœ¬ï¼ˆToken ä½¿ç”¨ï¼‰

### æ€§èƒ½ç“¶é¢ˆåˆ†æ

```
å…¸å‹ä»»åŠ¡è€—æ—¶åˆ†å¸ƒï¼ˆæ€»è®¡ ~120ç§’ï¼‰
â”œâ”€â”€ æœç´¢ (2ç§’) - 1.7%
â”œâ”€â”€ æ•´ç† (28ç§’) - 23.3%
â”œâ”€â”€ å†™ä½œ (36ç§’) - 30.0%
â”œâ”€â”€ è´¨æ£€ (114ç§’) - 95.0%  â† ä¸»è¦ç“¶é¢ˆ
â”‚   â”œâ”€â”€ LLM è°ƒç”¨ (100ç§’)
â”‚   â””â”€â”€ ç¡¬è§„åˆ™ (14ç§’)
â””â”€â”€ å›¾ç‰‡ç”Ÿæˆ (æœªé…ç½®)
```

**ä¼˜åŒ–é‡ç‚¹**: LLM è°ƒç”¨ã€ç¼“å­˜ç­–ç•¥ã€å¹¶å‘å¤„ç†

---

## ç¼“å­˜ä¼˜åŒ–

### 1. Redis ç¼“å­˜æ¶æ„

```typescript
// æ–‡ä»¶: src/infrastructure/cache/RedisCache.ts

import Redis from 'ioredis';
import { createLogger } from '../logging/logger.js';

const logger = createLogger('RedisCache');

export class RedisCache {
  private redis: Redis;
  private defaultTTL = 7 * 24 * 3600; // 7å¤©

  constructor(redis: Redis) {
    this.redis = redis;
  }

  async get<T>(key: string): Promise<T | null> {
    try {
      const value = await this.redis.get(key);
      if (!value) return null;

      return JSON.parse(value) as T;
    } catch (error) {
      logger.error('Cache get failed', { key, error });
      return null;
    }
  }

  async set(key: string, value: any, ttl?: number): Promise<void> {
    try {
      const serialized = JSON.stringify(value);
      const expiry = ttl || this.defaultTTL;

      await this.redis.setex(key, expiry, serialized);

      logger.debug('Cache set', { key, ttl: expiry });
    } catch (error) {
      logger.error('Cache set failed', { key, error });
    }
  }

  async delete(key: string): Promise<void> {
    try {
      await this.redis.del(key);
      logger.debug('Cache deleted', { key });
    } catch (error) {
      logger.error('Cache delete failed', { key, error });
    }
  }

  async invalidatePattern(pattern: string): Promise<void> {
    try {
      const keys = await this.redis.keys(pattern);
      if (keys.length > 0) {
        await this.redis.del(...keys);
        logger.info('Cache pattern invalidated', { pattern, count: keys.length });
      }
    } catch (error) {
      logger.error('Cache invalidate failed', { pattern, error });
    }
  }

  async mget<T>(keys: string[]): Promise<(T | null)[]> {
    try {
      const values = await this.redis.mget(...keys);
      return values.map(v => v ? JSON.parse(v) : null);
    } catch (error) {
      logger.error('Cache mget failed', { error });
      return keys.map(() => null);
    }
  }

  async mset(keyValuePairs: Record<string, any>, ttl?: number): Promise<void> {
    const pipeline = this.redis.pipeline();
    const expiry = ttl || this.defaultTTL;

    for (const [key, value] of Object.entries(keyValuePairs)) {
      const serialized = JSON.stringify(value);
      pipeline.setex(key, expiry, serialized);
    }

    await pipeline.exec();
  }

  // ç¼“å­˜ç»Ÿè®¡
  async getStats(pattern: string = 'cache:*'): Promise<CacheStats> {
    const keys = await this.redis.keys(pattern);
    const info = await this.redis.info('stats');

    return {
      totalKeys: keys.length,
      hits: parseInt(info.keyspace_hits || '0'),
      misses: parseInt(info.keyspace_misses || '0'),
      hitRate: (parseInt(info.keyspace_hits || '0') /
              (parseInt(info.keyspace_hits || '0') + parseInt(info.keyspace_misses || '1')))
    };
  }
}
```

### 2. ç¼“å­˜ç­–ç•¥

#### LLM å“åº”ç¼“å­˜

```typescript
// ç¼“å­˜ LLM ç”Ÿæˆç»“æœ
export class LLMCacheService {
  private cache: RedisCache;

  async getCachedResponse(prompt: string): Promise<string | null> {
    const key = this.generateKey('llm', prompt);
    return this.cache.get<string>(key);
  }

  async setCachedResponse(prompt: string, response: string): Promise<void> {
    const key = this.generateKey('llm', prompt);
    await this.cache.set(key, response, 7 * 24 * 3600); // 7å¤©
  }

  private generateKey(prefix: string, content: string): string {
    const hash = crypto.createHash('sha256')
      .update(content)
      .digest('hex')
      .substring(0, 16);
    return `${prefix}:${hash}`;
  }
}
```

#### æœç´¢ç»“æœç¼“å­˜

```typescript
export class SearchCacheService {
  private cache: RedisCache;

  async getCachedResults(query: string): Promise<SearchResult[] | null> {
    const key = this.generateKey('search', query);
    return this.cache.get<SearchResult[]>(key);
  }

  async setCachedResults(query: string, results: SearchResult[]): Promise<void> {
    const key = this.generateKey('search', query);
    await this.cache.set(key, results, 24 * 3600); // 1å¤©
  }
}
```

#### è´¨é‡æ£€æŸ¥ç¼“å­˜

```typescript
export class QualityCacheService {
  private cache: RedisCache;

  async getCachedEvaluation(content: string): Promise<QualityResult | null> {
    const key = this.generateKey('quality', content);
    return this.cache.get<QualityResult>(key);
  }

  async setCachedEvaluation(content: string, result: QualityResult): Promise<void> {
    const key = this.generateKey('quality', content);
    await this.cache.set(key, result, 3 * 24 * 3600); // 3å¤©
  }
}
```

### 3. ç¼“å­˜é¢„çƒ­

```typescript
// åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­å¸¸ç”¨æ•°æ®
export class CacheWarmupService {
  async warmup(): Promise<void> {
    logger.info('Starting cache warmup');

    // é¢„çƒ­å¸¸è§æŸ¥è¯¢çš„æœç´¢ç»“æœ
    const commonQueries = [
      'äººå·¥æ™ºèƒ½',
      'æœºå™¨å­¦ä¹ ',
      'æ·±åº¦å­¦ä¹ ',
      'è‡ªç„¶è¯­è¨€å¤„ç†'
    ];

    for (const query of commonQueries) {
      // å¼‚æ­¥é¢„çƒ­ï¼Œä¸é˜»å¡å¯åŠ¨
      this.warmupSearch(query).catch(err => {
        logger.warn('Cache warmup failed', { query, error: err });
      });
    }

    logger.info('Cache warmup completed');
  }

  private async warmupSearch(query: string): Promise<void> {
    const results = await this.searchService.search(query);
    await this.searchCache.setCachedResults(query, results);
  }
}
```

---

## æ•°æ®åº“ä¼˜åŒ–

### 1. ç´¢å¼•ä¼˜åŒ–

```sql
-- ä»»åŠ¡è¡¨ç´¢å¼•
CREATE INDEX idx_tasks_status_created ON tasks(status, created_at DESC);
CREATE INDEX idx_tasks_mode_status ON tasks(mode, status) WHERE status IN ('pending', 'processing');

-- ä»»åŠ¡æ­¥éª¤è¡¨ç´¢å¼•
CREATE INDEX idx_task_steps_task_step_status
ON task_steps(task_id, step_name, status);

-- Token ä½¿ç”¨è¡¨ç´¢å¼•
CREATE INDEX idx_token_usage_task_id ON token_usage(task_id);
CREATE INDEX idx_token_usage_created ON token_usage(created_at DESC);

-- è´¨é‡æ£€æŸ¥è¡¨ç´¢å¼•
CREATE INDEX idx_quality_checks_task_id ON quality_checks(task_id);
CREATE INDEX idx_quality_checks_score ON quality_checks(score) WHERE score < 7;
```

### 2. æŸ¥è¯¢ä¼˜åŒ–

```typescript
// ä½¿ç”¨è¿æ¥æ± 
import { Pool } from 'pg';

export class DatabaseService {
  private pool = new Pool({
    host: process.env.POSTGRES_HOST,
    port: parseInt(process.env.POSTGRES_PORT),
    database: process.env.POSTGRES_DB,
    user: process.env.POSTGRES_USER,
    password: process.env.POSTGRES_PASSWORD,
    max: 20, // æœ€å¤§è¿æ¥æ•°
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 2000,
  });

  // æ‰¹é‡æŸ¥è¯¢
  async getTasksWithSteps(taskIds: string[]): Promise<TaskWithSteps[]> {
    const client = await this.pool.connect();

    try {
      // ä½¿ç”¨ IN å­æŸ¥è¯¢é¿å… N+1 é—®é¢˜
      const query = `
        SELECT
          t.*,
          json_agg(
            json_build_object(
              'step_name', ts.step_name,
              'status', ts.status,
              'started_at', ts.started_at,
              'completed_at', ts.completed_at
            )
          ) as steps
        FROM tasks t
        LEFT JOIN task_steps ts ON t.id = ts.task_id
        WHERE t.id = ANY($1)
        GROUP BY t.id
      `;

      const result = await client.query(query, [taskIds]);
      return result.rows;
    } finally {
      client.release();
    }
  }

  // åˆ†é¡µæŸ¥è¯¢
  async getTasksPaginated(page: number, pageSize: number, filters: any): Promise<PaginatedResult> {
    const offset = (page - 1) * pageSize;
    const limit = pageSize;

    const [tasks, countResult] = await Promise.all([
      this.pool.query(
        'SELECT * FROM tasks WHERE $1 ORDER BY created_at DESC LIMIT $2 OFFSET $3',
        [filters.whereClause, limit, offset]
      ),
      this.pool.query(
        'SELECT COUNT(*) FROM tasks WHERE $1',
        [filters.whereClause]
      )
    ]);

    return {
      data: tasks.rows,
      total: parseInt(countResult.rows[0].count),
      page,
      pageSize,
      totalPages: Math.ceil(parseInt(countResult.rows[0].count) / pageSize)
    };
  }
}
```

### 3. è¿æ¥æ± é…ç½®

```typescript
// è¿æ¥æ± é…ç½®
const poolConfig = {
  // è¿æ¥æ•°
  max: 20,                    // æœ€å¤§è¿æ¥æ•°
  min: 5,                     // æœ€å°ç©ºé—²è¿æ¥æ•°
  idle: 10000,                // ç©ºé—²è¿æ¥è¶…æ—¶ï¼ˆ10ç§’ï¼‰

  // è¶…æ—¶
  connectionTimeoutMillis: 2000, // è¿æ¥è¶…æ—¶
  idleTimeoutMillis: 30000,      // ç©ºé—²è¶…æ—¶
  statementTimeout: 30000,       // æŸ¥è¯¢è¶…æ—¶ï¼ˆ30ç§’ï¼‰

  // é‡è¯•
  retries: 3,
};

// æ€§èƒ½ç›‘æ§
pool.on('connect', (client) => {
  logger.info('New DB client connected', { totalCount: pool.totalCount });
});

pool.on('error', (err) => {
  logger.error('DB client error', { error: err });
});

pool.on('remove', () => {
  logger.warn('DB client removed');
});

pool.on('wait', (count) => {
  logger.warn('Waiting for available DB connection', { waitingCount: count });
});
```

---

## LLM è°ƒç”¨ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```typescript
// æ‰¹é‡ç”Ÿæˆå¤šä¸ªå†…å®¹
export class BatchLLMService {
  async generateBatch(prompts: string[]): Promise<string[]> {
    const batchSize = 5; // æ¯æ‰¹å¤„ç†5ä¸ª
    const results: string[] = [];

    for (let i = 0; i < prompts.length; i += batchSize) {
      const batch = prompts.slice(i, i + batchSize);

      // å¹¶å‘å¤„ç†æ‰¹æ¬¡
      const batchResults = await Promise.all(
        batch.map(prompt => this.llmService.generate(prompt))
      );

      results.push(...batchResults);

      // æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…é€Ÿç‡é™åˆ¶
      if (i + batchSize < prompts.length) {
        await this.delay(1000); // ç­‰å¾…1ç§’
      }
    }

    return results;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### 2. Prompt ä¼˜åŒ–

```typescript
// ä¼˜åŒ– Prompt ä»¥å‡å°‘ Token ä½¿ç”¨
export class PromptOptimizer {
  optimizePrompt(prompt: string): string {
    // ç§»é™¤å†—ä½™ä¿¡æ¯
    let optimized = prompt
      .replace(/\s+/g, ' ')  // å¤šä¸ªç©ºæ ¼å‹ç¼©ä¸ºä¸€ä¸ª
      .trim();

    // ä½¿ç”¨æ›´ç®€æ´çš„è¡¨è¾¾
    const replacements = [
      ['è¯·', ''], // ç§»é™¤ç¤¼è²Œç”¨è¯­
      ['å¸®åŠ©æˆ‘', ''],
      ['æˆ‘éœ€è¦ä½ ', ''],
      ['ä½ èƒ½', ''],
      ['è¯·ç”Ÿæˆ', 'ç”Ÿæˆ'],
      ['è¯·æä¾›', 'æä¾›']
    ];

    for (const [from, to] of replacements) {
      optimized = optimized.replace(new RegExp(from, 'g'), to);
    }

    return optimized;
  }

  // ä¼°ç®— Token æ•°é‡
  estimateTokens(text: string): number {
    // ä¸­æ–‡çº¦ 1.5 å­—ç¬¦ = 1 token
    // è‹±æ–‡çº¦ 4 å­—ç¬¦ = 1 token
    const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
    const englishChars = text.length - chineseChars;

    return Math.ceil(chineseChars / 1.5 + englishChars / 4);
  }
}
```

### 3. æµå¼å“åº”

```typescript
// ä½¿ç”¨æµå¼å“åº”å‡å°‘é¦–å­—å»¶è¿Ÿ
export class StreamingLLMService {
  async *generateStream(prompt: string): AsyncGenerator<string> {
    const response = await fetch(this.llmBaseUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.model,
        messages: [{ role: 'user', content: prompt }],
        stream: true // å¯ç”¨æµå¼
      })
    });

    const reader = response.body!.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          yield data.choices[0].delta.content;
        }
      }
    }
  }

  // ä½¿ç”¨ç¤ºä¾‹
  async generateWithStreaming(prompt: string): Promise<string> {
    let fullResponse = '';

    for await (const chunk of this.generateStream(prompt)) {
      fullResponse += chunk;
      // å®æ—¶è¾“å‡ºåˆ°ç”¨æˆ·
      process.stdout.write(chunk);
    }

    return fullResponse;
  }
}
```

---

## å¹¶å‘ä¼˜åŒ–

### 1. Worker å¹¶å‘æ§åˆ¶

```typescript
// æ¯ä¸ª Worker çš„å¹¶å‘æ•°é…ç½®
export class WorkerConcurrencyManager {
  private concurrency: number;
  private runningTasks = 0;
  private queue: Array<() => Promise<any>> = [];

  constructor(concurrency: number = 2) {
    this.concurrency = concurrency;
  }

  async execute<T>(task: () => Promise<T>): Promise<T> {
    // å¦‚æœå·²æ»¡ï¼Œç­‰å¾…
    while (this.runningTasks >= this.concurrency) {
      await this.delay(100);
    }

    this.runningTasks++;

    try {
      return await task();
    } finally {
      this.runningTasks--;
    }
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### 2. ä»»åŠ¡åˆ†ç‰‡

```typescript
// å°†å¤§ä»»åŠ¡æ‹†åˆ†ä¸ºå°ä»»åŠ¡
export class TaskPartitioner {
  partition(content: string, maxLength: number = 3000): string[] {
    const chunks: string[] = [];
    let currentChunk = '';

    // æŒ‰æ®µè½åˆ†å‰²
    const paragraphs = content.split('\n\n');

    for (const paragraph of paragraphs) {
      if (currentChunk.length + paragraph.length > maxLength) {
        if (currentChunk) {
          chunks.push(currentChunk);
        }
        currentChunk = paragraph;
      } else {
        currentChunk += '\n\n' + paragraph;
      }
    }

    if (currentChunk) {
      chunks.push(currentChunk);
    }

    return chunks;
  }
}
```

### 3. å¹¶è¡Œå¤„ç†ç‹¬ç«‹ä»»åŠ¡

```typescript
// å¹¶è¡Œå¤„ç†å¤šä¸ªç‹¬ç«‹çš„è´¨é‡æ£€æŸ¥
export class ParallelQualityChecker {
  async checkParallel(content: string): Promise<CheckResult[]> {
    const checkers = [
      new WordCountChecker(),
      new KeywordChecker(),
      new StructureChecker(),
      new ForbiddenWordsChecker()
    ];

    // å¹¶è¡Œæ‰§è¡Œ
    const results = await Promise.all(
      checkers.map(checker =>
        this.executeWithTimeout(checker.check(content), 5000)
      )
    );

    return results;
  }

  private async executeWithTimeout<T>(
    fn: Promise<T>,
    timeout: number
  ): Promise<T> {
    return Promise.race([
      fn,
      new Promise<T>((_, reject) =>
        setTimeout(() => reject(new Error('Timeout')), timeout)
      )
    ]);
  }
}
```

---

## å†…å­˜ä¼˜åŒ–

### 1. æµå¼å¤„ç†

```typescript
// ä½¿ç”¨æµé¿å…å¤§æ–‡ä»¶å ç”¨å†…å­˜
import { Readable } from 'stream';

export class StreamingContentProcessor {
  async processLargeContent(stream: Readable): Promise<void> {
    const chunks: Buffer[] = [];

    return new Promise((resolve, reject) => {
      stream.on('data', (chunk: Buffer) => {
        chunks.push(chunk);

        // é™åˆ¶å†…å­˜ä½¿ç”¨
        const totalSize = chunks.reduce((sum, c) => sum + c.length, 0);
        if (totalSize > 10 * 1024 * 1024) { // 10MB
          stream.pause();
          // å¤„ç†å·²æ¥æ”¶çš„æ•°æ®
          this.processBatch(chunks);
          chunks.length = 0;
          stream.resume();
        }
      });

      stream.on('end', () => {
        this.processBatch(chunks);
        resolve();
      });

      stream.on('error', reject);
    });
  }

  private processBatch(chunks: Buffer[]): void {
    // å¤„ç†æ•°æ®æ‰¹æ¬¡
  }
}
```

### 2. å¯¹è±¡æ± 

```typescript
// å¤ç”¨æ˜‚è´µå¯¹è±¡
export class ObjectPool<T> {
  private pool: T[] = [];
  private factory: () => T;
  private reset?: (obj: T) => void;

  constructor(factory: () => T, reset?: (obj: T) => void, initialSize = 5) {
    this.factory = factory;
    this.reset = reset;

    for (let i = 0; i < initialSize; i++) {
      this.pool.push(factory());
    }
  }

  acquire(): T {
    if (this.pool.length > 0) {
      return this.pool.pop()!;
    }
    return this.factory();
  }

  release(obj: T): void {
    if (this.reset) {
      this.reset(obj);
    }
    this.pool.push(obj);
  }

  get size(): number {
    return this.pool.length;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const bufferPool = new ObjectPool(
  () => new Buffer(1024 * 1024), // 1MB buffer
  (buf) => buf.fill(0),
  5 // é¢„åˆ›å»º5ä¸ª
);
```

---

## ç½‘ç»œä¼˜åŒ–

### 1. HTTP è¿æ¥å¤ç”¨

```typescript
// ä½¿ç”¨ HTTP Agent å¤ç”¨è¿æ¥
import { Agent } from 'https';

const agent = new Agent({
  keepAlive: true,
  keepAliveMsecs: 60000,
  maxSockets: 100,
  maxFreeSockets: 10,
  timeout: 30000,
});

export class OptimizedHTTPClient {
  async fetch(url: string, options: RequestInit = {}): Promise<Response> {
    return fetch(url, {
      ...options,
      agent, // å¤ç”¨è¿æ¥
    });
  }
}
```

### 2. è¯·æ±‚åˆå¹¶

```typescript
// åˆå¹¶å¤šä¸ªè¯·æ±‚
export class RequestBatcher {
  private requests: Map<string, Promise<any>> = new Map();
  private pendingTimer?: NodeJS.Timeout;

  async batchRequest<T>(key: string, requestFn: () => Promise<T>): Promise<T> {
    // å¦‚æœå·²æœ‰ç›¸åŒè¯·æ±‚åœ¨ç­‰å¾…ï¼Œè¿”å›åŒä¸€ä¸ª Promise
    if (this.requests.has(key)) {
      return this.requests.get(key);
    }

    // åˆ›å»ºæ–°è¯·æ±‚
    const promise = requestFn().finally(() => {
      this.requests.delete(key);
    });

    this.requests.set(key, promise);

    return promise;
  }

  // å»¶è¿Ÿæ‰§è¡Œæ‰¹é‡æ“ä½œ
  scheduleBatch(key: string, fn: () => Promise<void>, delay: number = 100) {
    if (this.pendingTimer) {
      clearTimeout(this.pendingTimer);
    }

    this.pendingTimer = setTimeout(async () => {
      await fn();
      this.pendingTimer = undefined;
    }, delay);
  }
}
```

---

## æ€§èƒ½æµ‹è¯•

### 1. åŸºå‡†æµ‹è¯•

```typescript
// tests/performance/llm.bench.ts
import { Benchmark } from 'vitest';

describe('LLM Performance Benchmarks', () => {
  Benchmark('LLM generation', async (bench) => {
    const llmService = new LLMService();
    const prompt = 'æµ‹è¯•æç¤ºè¯';

    await bench('warmup', async () => {
      await llmService.generate(prompt);
    }, { iterations: 10, warmupIterations: 5 });

    await bench('normal', async () => {
      await llmService.generate(prompt);
    }, { iterations: 100 });
  });

  Benchmark('Cache performance', async (bench) => {
    const cache = new RedisCache();

    await bench('set', async () => {
      await cache.set('test-key', { data: 'test' });
    }, { iterations: 1000 });

    await bench('get', async () => {
      await cache.get('test-key');
    }, { iterations: 1000 });
  });
});
```

### 2. è´Ÿè½½æµ‹è¯•

```typescript
// tests/performance/load.test.ts
import { describe, it } from 'vitest';

describe('Load Tests', () => {
  it('should handle 100 concurrent tasks', async () => {
    const tasks = Array(100).fill(null).map((_, i) => ({
      mode: 'async',
      topic: `æµ‹è¯•ä»»åŠ¡ ${i}`,
      requirements: 'æµ‹è¯•æè¿°',
    }));

    const startTime = Date.now();

    const results = await Promise.all(
      tasks.map(task => scheduler.scheduleTask(task))
    );

    const duration = Date.now() - startTime;

    expect(duration).toBeLessThan(5000); // 5ç§’å†…å®Œæˆ
    expect(results).toHaveLength(100);
  });
});
```

### 3. æ€§èƒ½åˆ†æ

```typescript
// ä½¿ç”¨ Node.js profiler
import { performance } from 'perf_hooks';

export class PerformanceProfiler {
  startProfiling(id: string) {
    performance.mark(`${id}-start`);
  }

  endProfiling(id: string): number {
    performance.mark(`${id}-end`);
    performance.measure(id, `${id}-start`, `${id}-end`);

    const measure = performance.getEntriesByName(id)[0];
    return measure.duration;
  }

  // åˆ†æå†…å­˜ä½¿ç”¨
  getMemoryUsage(): NodeJS.MemoryUsage {
    return process.memoryUsage();
  }

  // GC è§¦å‘
  forceGC() {
    if (global.gc) {
      global.gc();
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const profiler = new PerformanceProfiler();

profiler.startProfiling('task-processing');
await processTask();
const duration = profiler.endProfiling('task-processing');
console.log(`Task took ${duration}ms`);

// å†…å­˜åˆ†æ
const memBefore = profiler.getMemoryUsage();
// ... æ‰§è¡Œæ“ä½œ
profiler.forceGC();
const memAfter = profiler.getMemoryUsage();
console.log(`Memory delta: ${memAfter.heapUsed - memBefore.heapUsed} bytes`);
```

---

## æ€§èƒ½æŒ‡æ ‡

### ç›®æ ‡æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | æ–¹æ³• |
|------|------|------|------|
| å•ä»»åŠ¡å»¶è¿Ÿ | ~120ç§’ | <90ç§’ | LLMç¼“å­˜ã€å¹¶è¡Œå¤„ç† |
| å¹¶å‘ä»»åŠ¡æ•° | 2 | 10 | å¢åŠ Workerå¹¶å‘ |
| å†…å­˜å ç”¨ | æœªçŸ¥ | <2GB | æµå¼å¤„ç†ã€å¯¹è±¡æ±  |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | >60% | å¤šçº§ç¼“å­˜ |
| API è°ƒç”¨æ¬¡æ•° | æœªçŸ¥ | -30% | ç»“æœç¼“å­˜ã€Promptä¼˜åŒ– |

### ç›‘æ§æŒ‡æ ‡

```typescript
// Prometheus æŒ‡æ ‡
const performanceMetrics = {
  // å“åº”æ—¶é—´
  taskDuration_p99: 300,      // 99åˆ†ä½ < 5åˆ†é’Ÿ
  llmRequestDuration_p95: 60,  // 95åˆ†ä½ < 1åˆ†é’Ÿ

  // ååé‡
  tasksPerMinute: 5,          // 5ä¸ªä»»åŠ¡/åˆ†é’Ÿ
  tasksPerDay: 7200,          // 7200ä¸ªä»»åŠ¡/å¤©ï¼ˆç†è®ºå€¼ï¼‰

  // ç¼“å­˜
  cacheHitRate_llm: 0.4,      // LLMç¼“å­˜å‘½ä¸­ç‡ > 40%
  cacheHitRate_search: 0.6,   // æœç´¢ç¼“å­˜å‘½ä¸­ç‡ > 60%

  // èµ„æº
  memoryUsage_heapUsed: 1024 * 1024 * 1024, // < 1GB
  cpuUsage_percent: 70,                    // < 70%
};
```

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2026-01-19
**ç‰ˆæœ¬**: 1.0
