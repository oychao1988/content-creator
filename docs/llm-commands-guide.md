# LLM æµ‹è¯•å‘½ä»¤ä½¿ç”¨æŒ‡å—

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›– .env é…ç½®

```bash
# ä½¿ç”¨ CLI æ¨¡å¼
LLM_SERVICE_TYPE=cli CLAUDE_CLI_ENABLED=true npx tsx scripts/quick-llm-test.ts

# ä½¿ç”¨ API æ¨¡å¼
LLM_SERVICE_TYPE=api npx tsx scripts/quick-llm-test.ts

# ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
LLM_SERVICE_TYPE=cli CLAUDE_CLI_DEFAULT_MODEL=opus npx tsx scripts/quick-llm-test.ts
```

### æ–¹å¼ 2ï¼šä½¿ç”¨ä¸“ç”¨è„šæœ¬

#### API æµ‹è¯•ï¼ˆå¼ºåˆ¶ä½¿ç”¨ DeepSeek APIï¼‰

```bash
# é»˜è®¤æç¤ºè¯
npm run test:llm:api

# è‡ªå®šä¹‰æç¤ºè¯
npx tsx scripts/test-api-llm.ts "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"
```

#### CLI æµ‹è¯•ï¼ˆå¼ºåˆ¶ä½¿ç”¨ Claude CLIï¼‰

```bash
# é»˜è®¤æç¤ºè¯
npm run test:llm:cli

# è‡ªå®šä¹‰æç¤ºè¯
npx tsx scripts/test-cli-llm.ts "ç”¨è‹±æ–‡ä»‹ç» Rust è¯­è¨€"
```

#### é€šç”¨æµ‹è¯•è„šæœ¬ï¼ˆæ”¯æŒå¤šç§é…ç½®ï¼‰

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆAPI æ¨¡å¼ï¼‰
npm run test:llm

# æŒ‡å®šæç¤ºè¯
npx tsx scripts/test-llm.ts "ä½ å¥½ï¼Œä¸–ç•Œ"

# ä½¿ç”¨ CLI æ¨¡å¼
npx tsx scripts/test-llm.ts "ä½ å¥½" --type cli

# ç¦ç”¨æµå¼è¾“å‡º
npx tsx scripts/test-llm.ts "ä½ å¥½" --no-stream

# ç¦ç”¨å®æ—¶æ˜¾ç¤º
npx tsx scripts/test-llm.ts "ä½ å¥½" --no-display

# æŸ¥çœ‹å¸®åŠ©
npx tsx scripts/test-llm.ts --help
```

### æ–¹å¼ 3ï¼šå¿«é€Ÿæµ‹è¯•ï¼ˆä½¿ç”¨ .env é…ç½®ï¼‰

```bash
# ä½¿ç”¨ .env ä¸­çš„é…ç½®
npm run test:llm:quick
```

## å‘½ä»¤å¯¹æ¯”

| å‘½ä»¤ | LLM ç±»å‹ | é…ç½®æ¥æº | æµå¼è¾“å‡º | å®æ—¶æ˜¾ç¤º |
|------|----------|----------|----------|----------|
| `npm run test:llm:quick` | .env é…ç½® | .env | âœ… | âœ… |
| `npm run test:llm:api` | API | å¼ºåˆ¶ API | âœ… | âœ… |
| `npm run test:llm:cli` | CLI | å¼ºåˆ¶ CLI | âœ… | âœ… |
| `npm run test:llm` | APIï¼ˆé»˜è®¤ï¼‰ | å‘½ä»¤è¡Œå‚æ•° | âœ… | âœ… |
| `LLM_SERVICE_TYPE=cli npm run test:llm:quick` | CLI | ç¯å¢ƒå˜é‡è¦†ç›– | âœ… | âœ… |

## å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šå¿«é€Ÿæµ‹è¯• API æ˜¯å¦æ­£å¸¸

```bash
npm run test:llm:api
```

### åœºæ™¯ 2ï¼šæµ‹è¯• Claude CLI æ˜¯å¦å¯ç”¨

```bash
npm run test:llm:cli
```

### åœºæ™¯ 3ï¼šæ¯”è¾ƒ API å’Œ CLI çš„è¾“å‡º

```bash
# API è¾“å‡º
npm run test:llm:api "ä»€ä¹ˆæ˜¯ TypeScriptï¼Ÿ"

# CLI è¾“å‡º
npm run test:llm:cli "ä»€ä¹ˆæ˜¯ TypeScriptï¼Ÿ"
```

### åœºæ™¯ 4ï¼šè‡ªå®šä¹‰æç¤ºè¯æµ‹è¯•

```bash
# ä½¿ç”¨é€šç”¨è„šæœ¬
npx tsx scripts/test-llm.ts "å†™ä¸€é¦–å…³äºAIçš„è¯—" --type api

# ä½¿ç”¨ä¸“ç”¨è„šæœ¬
npx tsx scripts/test-api-llm.ts "å†™ä¸€é¦–å…³äºAIçš„è¯—"
```

### åœºæ™¯ 5ï¼šåœ¨å·¥ä½œæµä¸­ä½¿ç”¨ä¸åŒçš„ LLM

```bash
# ä½¿ç”¨ API æ¨¡å¼è¿è¡Œå·¥ä½œæµ
LLM_SERVICE_TYPE=api npm run cli create -- --topic "æµ‹è¯•" --requirements "å†™ä¸€ç¯‡æ–‡ç« "

# ä½¿ç”¨ CLI æ¨¡å¼è¿è¡Œå·¥ä½œæµ
LLM_SERVICE_TYPE=cli CLAUDE_CLI_ENABLED=true npm run cli create -- --topic "æµ‹è¯•" --requirements "å†™ä¸€ç¯‡æ–‡ç« "
```

## ç¯å¢ƒå˜é‡å‚è€ƒ

å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­è¦†ç›–ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
# LLM æœåŠ¡ç±»å‹
LLM_SERVICE_TYPE=api              # api æˆ– cli

# API é…ç½®
LLM_API_KEY=your_key
LLM_BASE_URL=https://api.example.com
LLM_MODEL_NAME=deepseek-chat
LLM_MAX_TOKENS=4000
LLM_TEMPERATURE=0.7
LLM_TIMEOUT_MS=60000
LLM_STREAM_TIMEOUT_MS=120000

# CLI é…ç½®
CLAUDE_CLI_ENABLED=true
CLAUDE_CLI_DEFAULT_MODEL=sonnet   # sonnet æˆ– opus
CLAUDE_CLI_DEFAULT_TIMEOUT=180000

# æ—¥å¿—é…ç½®
LOG_LEVEL=debug                   # debug, info, warn, error
```

## ç¤ºä¾‹è¾“å‡º

### Debug æ¨¡å¼ + æµå¼æ˜¾ç¤º

```bash
LOG_LEVEL=debug npm run test:llm:api
```

è¾“å‡ºï¼š
```
ğŸ§ª LLM æœåŠ¡æµ‹è¯•
==================================================
ğŸ“ æç¤ºè¯: è¯·ç”¨ä¸€å¥è¯ä»‹ç» TypeScript

â³ æ­£åœ¨ç”Ÿæˆ...

ğŸ’¬ å›å¤:
2026-02-01 13:14:43 [debug]: [LLMFactory] Creating LLM service {"type":"api"}
2026-02-01 13:14:43 [info]: [LLMFactory] Creating Enhanced LLM API service
2026-02-01 13:14:43 [debug]: [LLM:Enhanced] Starting stream request
TypeScript æ˜¯ JavaScript çš„ä¸€ä¸ªè¶…é›†ï¼Œæ·»åŠ äº†é™æ€ç±»å‹ç³»ç»Ÿï¼Œä½¿ä»£ç æ›´æ˜“ç»´æŠ¤å’Œé€‚åˆå¤§å‹é¡¹ç›®å¼€å‘ã€‚
2026-02-01 13:14:47 [debug]: [LLM:Enhanced] Stream request completed

âœ… ç”ŸæˆæˆåŠŸ!

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
   - Token ä½¿ç”¨: 38 (è¾“å…¥: 10, è¾“å‡º: 28)
   - è€—æ—¶: 4.09s
   - æˆæœ¬: $0.000066
```

## æ•…éšœæ’é™¤

### CLI è¶…æ—¶

å¦‚æœ CLI æ¨¡å¼è¶…æ—¶ï¼š
1. ç¡®ä¿å·²å®‰è£… Claude CLIï¼š`npm install -g @anthropic-ai/claude-code`
2. ç¡®ä¿å·²è®¤è¯ï¼š`claude setup-token`
3. å¢åŠ è¶…æ—¶æ—¶é—´ï¼š`CLAUDE_CLI_DEFAULT_TIMEOUT=300000`

### API è¶…æ—¶

å¦‚æœ API æ¨¡å¼è¶…æ—¶ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆ
3. å¢åŠ è¶…æ—¶æ—¶é—´ï¼š`LLM_STREAM_TIMEOUT_MS=180000`
4. å¯ç”¨ debug æ—¥å¿—æŸ¥çœ‹è¯¦æƒ…ï¼š`LOG_LEVEL=debug`

### æµå¼æ˜¾ç¤ºä¸å·¥ä½œ

ç¡®ä¿ï¼š
1. ä½¿ç”¨ `stream: true` å‚æ•°
2. ä½¿ç”¨ `enableStreamDisplay: true` å‚æ•°
3. å‘½ä»¤è¡Œæ”¯æŒ ANSI è¾“å‡ºï¼ˆå¤§å¤šæ•°ç»ˆç«¯éƒ½æ”¯æŒï¼‰

## è„šæœ¬æ–‡ä»¶è¯´æ˜

- `scripts/quick-llm-test.ts` - å¿«é€Ÿæµ‹è¯•ï¼ˆä½¿ç”¨ .env é…ç½®ï¼‰
- `scripts/test-api-llm.ts` - API æµ‹è¯•ï¼ˆå¼ºåˆ¶ä½¿ç”¨ APIï¼‰
- `scripts/test-cli-llm.ts` - CLI æµ‹è¯•ï¼ˆå¼ºåˆ¶ä½¿ç”¨ CLIï¼‰
- `scripts/test-llm.ts` - é€šç”¨æµ‹è¯•ï¼ˆæ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼‰
