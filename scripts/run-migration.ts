/**
 * æ•°æ®åº“è¿ç§»è¿è¡Œè„šæœ¬
 *
 * ç”¨æ³•:
 *   pnpm run migrate        # è¿è¡Œæ‰€æœ‰è¿ç§»
 *   pnpm run migrate:undo   # å›æ»šæœ€åä¸€ä¸ªè¿ç§»
 *   pnpm run migrate:status # æŸ¥çœ‹è¿ç§»çŠ¶æ€
 */

import { config } from 'dotenv';
import { Pool } from 'pg';
import { readFileSync } from 'fs';
import { join } from 'path';
import { fileURLToPath } from 'url';

// åŠ è½½ç¯å¢ƒå˜é‡
config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = join(__filename, '..');

// æ•°æ®åº“è¿æ¥é…ç½®
let password = process.env.POSTGRES_PASSWORD || '';
// å»é™¤å¯†ç ä¸­çš„å¼•å·ï¼ˆå¦‚æœæœ‰ï¼‰
password = password.replace(/^['"]|['"]$/g, '');

const pool = new Pool({
  host: process.env.POSTGRES_HOST || 'localhost',
  port: parseInt(process.env.POSTGRES_PORT || '5432'),
  database: process.env.POSTGRES_DB || 'postgres',
  user: process.env.POSTGRES_USER || 'postgres',
  password,
});

/**
 * æ‰§è¡Œ SQL æ–‡ä»¶
 */
async function executeSqlFile(sqlPath: string): Promise<void> {
  const sql = readFileSync(sqlPath, 'utf-8');

  console.log(`ğŸ“„ æ‰§è¡Œ SQL æ–‡ä»¶: ${sqlPath}`);

  try {
    await pool.query(sql);
    console.log('âœ… SQL æ‰§è¡ŒæˆåŠŸ');
  } catch (error) {
    console.error('âŒ SQL æ‰§è¡Œå¤±è´¥:', error);
    throw error;
  }
}

/**
 * è¿è¡Œè¿ç§»
 */
async function runMigration(): Promise<void> {
  console.log('ğŸš€ å¼€å§‹è¿è¡Œæ•°æ®åº“è¿ç§»...\n');

  try {
    const migrationPath = join(__dirname, '../migrations/001_create_initial_tables.sql');
    await executeSqlFile(migrationPath);

    console.log('\nâœ¨ è¿ç§»å®Œæˆ!');
  } catch (error) {
    console.error('\nâŒ è¿ç§»å¤±è´¥:', error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

/**
 * å›æ»šè¿ç§»
 */
async function rollbackMigration(): Promise<void> {
  console.log('ğŸ”„ å¼€å§‹å›æ»šæ•°æ®åº“è¿ç§»...\n');

  try {
    const rollbackPath = join(__dirname, '../migrations/001_rollback.sql');
    await executeSqlFile(rollbackPath);

    console.log('\nâœ¨ å›æ»šå®Œæˆ!');
  } catch (error) {
    console.error('\nâŒ å›æ»šå¤±è´¥:', error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

/**
 * æŸ¥çœ‹è¿ç§»çŠ¶æ€
 */
async function checkMigrationStatus(): Promise<void> {
  console.log('ğŸ“Š æŸ¥è¯¢è¿ç§»çŠ¶æ€...\n');

  try {
    const result = await pool.query(`
      SELECT version, description, executed_at
      FROM schema_migrations
      ORDER BY executed_at DESC
    `);

    if (result.rows.length === 0) {
      console.log('â„¹ï¸  å°šæœªè¿è¡Œä»»ä½•è¿ç§»');
    } else {
      console.table(result.rows);
    }

    console.log('\nå½“å‰æ•°æ®åº“è¡¨:');
    const tables = await pool.query(`
      SELECT table_name
      FROM information_schema.tables
      WHERE table_schema = 'public'
      ORDER BY table_name
    `);

    console.log(tables.rows.map((r: any) => `  - ${r.table_name}`).join('\n'));
  } catch (error) {
    console.error('âŒ æŸ¥è¯¢å¤±è´¥:', error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

/**
 * ä¸»å‡½æ•°
 */
async function main(): Promise<void> {
  const command = process.argv[2] || 'run';

  switch (command) {
    case 'run':
    case 'migrate':
      await runMigration();
      break;
    case 'undo':
    case 'rollback':
      await rollbackMigration();
      break;
    case 'status':
      await checkMigrationStatus();
      break;
    default:
      console.log(`
ç”¨æ³•:
  pnpm run migrate        # è¿è¡Œæ‰€æœ‰è¿ç§»
  pnpm run migrate:undo   # å›æ»šæœ€åä¸€ä¸ªè¿ç§»
  pnpm run migrate:status # æŸ¥çœ‹è¿ç§»çŠ¶æ€

  æˆ–ç›´æ¥ä½¿ç”¨:
  node scripts/run-migration.ts [run|undo|status]
      `);
      process.exit(1);
  }
}

// è¿è¡Œä¸»å‡½æ•°
main().catch((error) => {
  console.error('æœªæ•è·çš„é”™è¯¯:', error);
  process.exit(1);
});
