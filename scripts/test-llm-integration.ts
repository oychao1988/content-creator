#!/usr/bin/env tsx
/**
 * LLM æœåŠ¡å¿«é€Ÿæµ‹è¯•è„šæœ¬
 *
 * æµ‹è¯• API å’Œ CLI æ¨¡å¼çš„æµå¼/éæµå¼è¾“å‡º
 *
 * è¿è¡Œæ–¹å¼ï¼š
 * - æµ‹è¯• API æ¨¡å¼ï¼šnpm run test-llm
 * - æµ‹è¯• CLI æ¨¡å¼ï¼šLLM_SERVICE_TYPE=cli npm run test-llm
 * - å¯ç”¨è¯¦ç»†è¾“å‡ºï¼šnpm run test-llm -- --verbose
 */

import { LLMServiceFactory } from '../src/services/llm/LLMServiceFactory.js';
import { config } from '../src/config/index.js';

const VERBOSE = process.argv.includes('--verbose');

async function testAPIMode() {
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ§ª æµ‹è¯• API æ¨¡å¼ (EnhancedLLMService)');
  console.log('='.repeat(60));

  const apiService = LLMServiceFactory.createAPI();

  // éæµå¼æµ‹è¯•
  console.log('\nğŸ“ æµ‹è¯• 1: éæµå¼æ¨¡å¼');
  console.log('-'.repeat(40));
  const streamStart1 = Date.now();
  const nonStreamResult = await apiService.chat({
    messages: [
      { role: 'user', content: 'ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ RESTful API' },
    ],
    stream: false,
  });
  const streamDuration1 = Date.now() - streamStart1;

  console.log('âœ… å“åº”é•¿åº¦:', nonStreamResult.content.length, 'å­—ç¬¦');
  console.log('âœ… Token ä½¿ç”¨:', nonStreamResult.usage.totalTokens);
  console.log('âœ… æˆæœ¬: $' + nonStreamResult.cost.toFixed(6));
  console.log('âœ… è€—æ—¶:', (streamDuration1 / 1000).toFixed(2) + 's');

  if (VERBOSE) {
    console.log('\nğŸ“„ å“åº”å†…å®¹:');
    console.log(nonStreamResult.content.substring(0, 200) + '...');
  }

  // æµå¼æµ‹è¯•
  console.log('\nğŸ“ æµ‹è¯• 2: æµå¼æ¨¡å¼');
  console.log('-'.repeat(40));
  const streamStart2 = Date.now();
  const streamResult = await apiService.chat({
    messages: [
      { role: 'user', content: 'åˆ—ä¸¾ä¸‰ç§å¸¸è§çš„è®¾è®¡æ¨¡å¼' },
    ],
    stream: true,
  });
  const streamDuration2 = Date.now() - streamStart2;

  console.log('âœ… å“åº”é•¿åº¦:', streamResult.content.length, 'å­—ç¬¦');
  console.log('âœ… Token ä½¿ç”¨:', streamResult.usage.totalTokens);
  console.log('âœ… æˆæœ¬: $' + streamResult.cost.toFixed(6));
  console.log('âœ… è€—æ—¶:', (streamDuration2 / 1000).toFixed(2) + 's');

  if (VERBOSE) {
    console.log('\nğŸ“„ å“åº”å†…å®¹:');
    console.log(streamResult.content.substring(0, 200) + '...');
  }

  // å¯¹æ¯”
  console.log('\nğŸ“Š å¯¹æ¯”åˆ†æ');
  console.log('-'.repeat(40));
  const tokenDiff = Math.abs(
    streamResult.usage.totalTokens - nonStreamResult.usage.totalTokens
  );
  console.log('Token å·®å¼‚:', tokenDiff, '(æµå¼ vs éæµå¼)');
}

async function testCLIMode() {
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ§ª æµ‹è¯• CLI æ¨¡å¼ (ClaudeCLIService)');
  console.log('='.repeat(60));

  const cliService = LLMServiceFactory.createCLI();

  // éæµå¼æµ‹è¯•
  console.log('\nğŸ“ æµ‹è¯• 1: éæµå¼æ¨¡å¼');
  console.log('-'.repeat(40));
  const streamStart1 = Date.now();
  const nonStreamResult = await cliService.chat({
    messages: [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶' },
      { role: 'user', content: 'è§£é‡Šä»€ä¹ˆæ˜¯ TypeScript' },
    ],
    stream: false,
  });
  const streamDuration1 = Date.now() - streamStart1;

  console.log('âœ… å“åº”é•¿åº¦:', nonStreamResult.content.length, 'å­—ç¬¦');
  console.log('âœ… Token ä½¿ç”¨:', nonStreamResult.usage.totalTokens);
  console.log('âœ… æˆæœ¬: $' + nonStreamResult.cost.toFixed(6));
  console.log('âœ… è€—æ—¶:', (streamDuration1 / 1000).toFixed(2) + 's');

  if (VERBOSE) {
    console.log('\nğŸ“„ å“åº”å†…å®¹:');
    console.log(nonStreamResult.content.substring(0, 200) + '...');
  }

  // æµå¼æµ‹è¯•
  console.log('\nğŸ“ æµ‹è¯• 2: æµå¼æ¨¡å¼');
  console.log('-'.repeat(40));
  const streamStart2 = Date.now();
  const streamResult = await cliService.chat({
    messages: [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶' },
      { role: 'user', content: 'åˆ—ä¸¾ä¸‰ç§æ•°æ®åº“ç±»å‹' },
    ],
    stream: true,
  });
  const streamDuration2 = Date.now() - streamStart2;

  console.log('âœ… å“åº”é•¿åº¦:', streamResult.content.length, 'å­—ç¬¦');
  console.log('âœ… Token ä½¿ç”¨:', streamResult.usage.totalTokens);
  console.log('âœ… æˆæœ¬: $' + streamResult.cost.toFixed(6));
  console.log('âœ… è€—æ—¶:', (streamDuration2 / 1000).toFixed(2) + 's');

  if (VERBOSE) {
    console.log('\nğŸ“„ å“åº”å†…å®¹:');
    console.log(streamResult.content.substring(0, 200) + '...');
  }
}

async function healthCheck() {
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ¥ å¥åº·æ£€æŸ¥');
  console.log('='.repeat(60));

  const service = LLMServiceFactory.create();

  console.log('\næ£€æŸ¥æœåŠ¡:', config.llmServiceType.toUpperCase());
  const isHealthy = await service.healthCheck();

  if (isHealthy) {
    console.log('âœ… æœåŠ¡å¥åº·');
  } else {
    console.log('âŒ æœåŠ¡ä¸å¥åº·');
    process.exit(1);
  }
}

async function main() {
  try {
    console.log('\nğŸš€ LLM æœåŠ¡é›†æˆæµ‹è¯•');
    console.log('å½“å‰é…ç½®: LLM_SERVICE_TYPE=' + config.llmServiceType);
    console.log('è¿è¡Œæ¨¡å¼:', config.llmServiceType === 'cli' ? 'Claude CLI' : 'DeepSeek API');

    // å¥åº·æ£€æŸ¥
    await healthCheck();

    // æ ¹æ®é…ç½®è¿è¡Œç›¸åº”æµ‹è¯•
    if (config.llmServiceType === 'cli') {
      await testCLIMode();
    } else {
      await testAPIMode();
    }

    console.log('\n' + '='.repeat(60));
    console.log('âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼');
    console.log('='.repeat(60) + '\n');
  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:', error);
    process.exit(1);
  }
}

main();
