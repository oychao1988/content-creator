#!/usr/bin/env tsx
/**
 * API LLM æœåŠ¡æµ‹è¯•è„šæœ¬
 * ä½¿ç”¨ DeepSeek API ç”Ÿæˆå†…å®¹
 */

import { LLMServiceFactory } from '../src/services/llm/LLMServiceFactory.js';
import type { ILLMService } from '../src/services/llm/ILLMService.js';

// ä»å‘½ä»¤è¡Œå‚æ•°è¯»å–æç¤ºè¯
const prompt = process.argv[2] || 'è¯·ç”¨ä¸€å¥è¯ä»‹ç» TypeScript';

async function testAPI() {
  console.log('\nğŸŒ API LLM æœåŠ¡æµ‹è¯•');
  console.log('=' .repeat(50));
  console.log(`ğŸ“ æç¤ºè¯: ${prompt}\n`);
  console.log('â³ æ­£åœ¨ç”Ÿæˆ...\n');
  console.log('ğŸ’¬ å›å¤: ');

  try {
    const startTime = Date.now();

    // å¼ºåˆ¶ä½¿ç”¨ API æœåŠ¡
    const apiService: ILLMService = LLMServiceFactory.createAPI();

    const result = await apiService.chat({
      messages: [{ role: 'user', content: prompt }],
      stream: true,
      enableStreamDisplay: true,
    });

    const duration = Date.now() - startTime;

    console.log('\nâœ… ç”ŸæˆæˆåŠŸ!\n');
    console.log('ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:');
    console.log(`   - Token ä½¿ç”¨: ${result.usage.totalTokens} (è¾“å…¥: ${result.usage.promptTokens}, è¾“å‡º: ${result.usage.completionTokens})`);
    console.log(`   - è€—æ—¶: ${(duration / 1000).toFixed(2)}s`);
    console.log(`   - æˆæœ¬: $${result.cost.toFixed(6)}\n`);
  } catch (error) {
    console.error('\nâŒ ç”Ÿæˆå¤±è´¥:', error);
    process.exit(1);
  }
}

testAPI();
